---
layout:     post
title:      "聚类分析"
subtitle:   " \"常见的聚类分析算法以及在spss中的使用\""
date:       2018-08-11 17:40:00
author:     "Rumia"
header-img: "img/post-bg-hello.jpg"
catalog: true
category: blog
tags:
    - 机器学习
    - 无监督学习
    - spss
---

> 先写在这里提醒我自己，以后写写东西随手按一下 **ctrl+s**。。。

## 定义

聚类分析指将物理或抽象对象的集合**分组**为由类似的对象组成的多个类的分析过程。 在数学，计算机科学，经济学，统计学，以及机器学习领域有着广泛的应用。

### 与**分类**的区别

数据分类是分析已有的数据，寻找其共同的属性，并根据分类模型将这些数据划分成不同的类别，这些数据赋予类标号。这些类别是事先定义好的，并且类别数是已知的。相反，数据聚类则是将本没有类别参考的数据进行分析并划分为不同的组，即从这些数据导出类标号。聚类分析本身则是根据数据来发掘数据对象及其关系信息，并将这些数据分组。每个组内的对象之间是相似的，而各个组间的对象是不相关的。不难理解，组内相似性越高，组间相异性越高，则聚类越好 。聚类是无监督学习，就是把未标记的数据集通过算法的方式加以标记，而分类是监督学习。

### 常用算法

#### k-means算法（快速聚类）

- 定义

   k-means算法是一种简单的迭代型聚类算法，采用距离作为相似性指标，从而发现给定数据集中的K个类，且每个类的中心是根据类中所有值的均值得到，每个类用聚类中心来描述。对于给定的一个包含n个d维数据点的数据集X以及要分得的类别K,选取欧式距离作为相似度指标，聚类目标是使得各类的聚类平方和最小，即最小化： 

$$
J=\sum_{k=1}^k\sum_{i=1}^n\|x_i-u_k\|^2
$$

​	结合最小二乘法和拉格朗日原理，聚类中心为对应类别中各数据点的平均值，同   时为了使得算法收敛，在迭代过程中，应使最终的聚类中心尽可能的不变。 

- 算法流程

  K-means是一个**反复迭代**的过程，算法分为四个步骤：

  1） 选取数据空间中的K个对象作为**初始中心**，每个对象代表一个聚类中心；

  2） 对于样本中的数据对象，根据它们与这些聚类中心的[欧氏距离](https://baike.baidu.com/item/%E6%AC%A7%E5%87%A0%E9%87%8C%E5%BE%97%E5%BA%A6%E9%87%8F/1274107?fromtitle=%E6%AC%A7%E6%B0%8F%E8%B7%9D%E7%A6%BB&fromid=1798948&fr=aladdin)，按距离最近的准则（贪心）将它们分到 **距离它们最近的聚类中心**（最相似）所对应的类；

  3） **更新**聚类中心：将每个类别中所有对象所对应的均值作为该类别的聚类中心，计算目标函数的值；

  4） 判断聚类中心和目标函数的值是否发生改变，若不变，则输出结果，若改变，则返回2）(迭代)

  

- spss操作及注意事项

  分析 -->分类 -->k均值聚类 -->选定聚类数(K) -->(迭代-->设定最大迭代次数，大一点无妨)

  由于数据的量纲不同，所以有些情况下会对聚类结果造成较大误差，所以需要做一下标准化：

  分析-->描述统计 --> 描述(勾选将标准化得分另存为变量)   

  

  - 小结

  1. 算法原理简单，只需要一个参数k，但是这个参数k在有些情况下是不容易选定的
  2. 受初值影响较大
  3. 在大数据样本下也能保证一定的准确性，但是算法的时间复杂度较高
  4. 对离群点较敏感
  5.  K-modes算法可以实现对离散数据的快速聚类

  

  #### 层次聚类（系统聚类）Hierarchical Clustering

  K-means算法是一种方便好用的算法，但是有**K值选择**和**聚类中心点选择**的问题，会在一定程度上影响聚类效果，为了避免这种问题可以采用层次聚类。首先考虑欧式空间下的层次聚类。该算法仅可用于规模相对较小的数据集。层次聚类用于非欧式空间时，还有一些与层次聚类相关的额外问题需要考虑。因此，当不存在簇质心或者说簇平均点时，可以考虑采用簇中心点（clustroid）来表示一个簇。 

  - spss

    spss下仅提供了合并法，大致过程如下

    1. 首先将各聚类单位各自作为一类(此时有n类)，按照所定义的距离计算各数据点之间的距离，形成一个距离阵

    2. 将距离最近的两个单位并为一个类别，形成n-1个类别，计算新产生的类别与其他各类别之间的距离或者相似度（这涉及如何计算两个类别之间[距离](https://blog.csdn.net/Kevin_cc98/article/details/73742037)或者相似度的问题，习惯上使用[Pearson相关系数](https://baike.baidu.com/item/Pearson%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B0/6243913?fr=aladdin)），形成新的距离阵。

    3. 按照和第二部相同的原则，再将距离最接近的两个类别合并，这是如果类别个数仍然大于1，则重复该步骤，直到所有数据都被合并成一个类别为止。

       

  层级聚类法的优点非常明显：可以对变量或者case进行聚类，变量可以为连续或分类变量，提供的距离测量方法和结果表示方法也非常丰富，但是，由于要反复计算距离，当样本量过大或者变量较多时，采用层次聚类运算速度明显较慢，不过现金计算机硬件水平提高已经使得其不再明显。

  

  - 进一步的讨论

  1. 各种层次聚类方法

     在层次聚类法中，当每个类别由多于一个的数据点构成时，就会涉及如何定义两个类别间距离的问题，距离的定义的不同会得到不同的分析结果，这也就构成了不同的层次聚类方法，常用的有一下几种。

     (1).最短距离法、中位数法、最长距离法

     (2).重心法

     (3).组内连接法、组间连接法

     (4).Ward法

     实践证明，默认的组间平均距离法就是一种非常优秀的方法，使用即可

  2. 利用标准化来调整聚类模式

     以案例(case)聚类为例，按照默认设定，分析的基本模式是保证用于聚类的变量在类别内的取值差异大。事实上，这只是聚类分析的一种角度，另一个角度，就是按照变量取值的变化模式来进行聚类。

     在spss中实现按照变量取值的变化模式来进行聚类是通过对变量进行**不同标准化**的方式来进行的，在spss中，默认的变量标准化是以变量的均数和标准差等统计量作为参照来进行的。如果选择了以案例的均属和标准差等统计量作为参照来进行并进行聚类，就会得到按照数据的取值模式而得到的聚类结果。具体在操作上，出对数据进行行列转置外，还可以通过将变量标准化的方法改为按照案例来进行，即在“方法”对话框左下角的“转换值”选项组中，要求数据“**按个案**”而不是“**按变量”**进行聚类即可。



参考文献：

[1]张文彤《spss20.0统计分析高级教程第二版》288页

[2]https://www.cnblogs.com/xmeo/p/6543057.html
